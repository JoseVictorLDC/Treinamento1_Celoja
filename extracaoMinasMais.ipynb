{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extração da Drogaria Minas Mais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4818/62150564.py:6: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capturando todas as URLs\n",
    "\n",
    "# Função de acessar site\n",
    "all_workers = os.cpu_count()\n",
    "\n",
    "def access_site(url, max_attempts=all_workers):\n",
    "    headers = {'Accept': '*/*', 'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
    "    for retry in range(max_attempts):\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers)\n",
    "            if response.status_code == 200:\n",
    "                return response\n",
    "        except Exception as e:\n",
    "                print(f\"An error occurred while accessing URL: {url}: {e}. Retrying... (Attempt {retry + 1}/{max_attempts})\")\n",
    "                time.sleep(1)\n",
    "\n",
    "# Função captura de todos os nomes de marcas e criação de URLs\n",
    "def getNomeMarcas():\n",
    "    response = access_site(\"https://www.drogariasminasmais.com.br/medicamentos\")\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    sessaoMarcasGrandes = soup.find('div', class_='vtex-search-result-3-x-filter__container vtex-search-result-3-x-filter__container--responsive-result-content-mz0001 bb b--muted-4 vtex-search-result-3-x-filter__container--brand')\n",
    "    sessaoMarcas = sessaoMarcasGrandes.find('div', class_='vtex-search-result-3-x-filterTemplateOverflow vtex-search-result-3-x-filterTemplateOverflow--responsive-result-content-mz0001 pb5 overflow-y-auto')\n",
    "    marcas = sessaoMarcas.find_all('label', class_='vtex-checkbox__label w-100 c-on-base pointer')\n",
    "    return marcas\n",
    "\n",
    "# Criando uma lista de URLs ainda não bem estruturadas\n",
    "urlSuja = getNomeMarcas()\n",
    "urlLimpa = []\n",
    "\n",
    "# Limpando lista das URLs\n",
    "for i in urlSuja:\n",
    "    # Criando texto separado e minusculo com \"-\"\n",
    "    texto = i.text.lower()\n",
    "    textoNovo = texto.replace(\" \", \"-\")\n",
    "    textoNovissimo = textoNovo.replace(\"/\", \"-\")\n",
    "\n",
    "    # Salvando tudo em uma lista\n",
    "    urlLimpa.append(textoNovissimo)\n",
    "\n",
    "listaUrls = []\n",
    "\n",
    "# Criando todas as URLs\n",
    "for j in urlLimpa:\n",
    "    URL = \"https://www.drogariasminasmais.com.br/medicamentos/\" + j + \"?initialMap=c&initialQuery=medicamentos&map=category-1,brand&page=\"\n",
    "    listaUrls.append(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para encontrar um arquivo JSON secreto dependendo da página e da marca\n",
    "def getJSON(urlInicial, page_number):\n",
    "    url = str(urlInicial) + str(page_number)\n",
    "    requisicao = requests.get(url)\n",
    "    soup = BeautifulSoup(requisicao.text, 'html.parser')\n",
    "    jsonSujo = soup.find_all('script')[-34].text\n",
    "    print(jsonSujo)\n",
    "    return jsonSujo\n",
    "\n",
    "total_pages = 25\n",
    "listaJSON = []\n",
    "\n",
    "# Iteração por páginas de usuários\n",
    "for i in listaUrls: \n",
    "    for page_number in range(1, total_pages + 1):\n",
    "        listaJSON.append(getJSON(i, page_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o JSON e capturando todos os códigos de produtos\n",
    "ean = []\n",
    "precoComDesconto = []\n",
    "precoSemDesconto = []\n",
    "desconto = []\n",
    "marcas = []\n",
    "\n",
    "for k in listaJSON:\n",
    "    jsonFiltrado = k[3545215:-8]\n",
    "    dados = json.loads(jsonFiltrado)\n",
    "    listaProdutos = []\n",
    "    listaProdutosCerta = []\n",
    "    listaProdutosSuperCerta = []\n",
    "    j = 0 \n",
    "\n",
    "    for i in dados.keys():\n",
    "        if j % 18 == 0:\n",
    "            listaProdutos.append(i)\n",
    "        j = j + 1\n",
    "        if j == 270:\n",
    "            break\n",
    "\n",
    "    for i in listaProdutos:\n",
    "        listaProdutosCerta.append(i.split(\".\")[0])\n",
    "\n",
    "    for i in listaProdutosCerta:\n",
    "        listaProdutosSuperCerta.append(i.replace(\"$\", \"\"))\n",
    "    \n",
    "    # Pegando todos os dados dos produtos\n",
    "    for i in listaProdutosSuperCerta:\n",
    "        marcas.append(dados[i][\"brand\"])\n",
    "\n",
    "    for i in listaProdutosSuperCerta:\n",
    "        # Parte do JSON que tem o EAN e precos\n",
    "        localJson1 = str(i) + '.items({\"filter\":\"ALL\"}).0'\n",
    "        dadosDesejados1 = dados.get(localJson1)\n",
    "\n",
    "        ean.append(dadosDesejados1[\"ean\"])\n",
    "\n",
    "    for i in listaProdutosSuperCerta:\n",
    "        # Parte do JSON que tem o EAN e precos\n",
    "        localJson2 = \"$\" + str(i) + '.items({\"filter\":\"ALL\"}).0.sellers.0.commertialOffer'\n",
    "        dadosDesejados2 = dados.get(localJson2)\n",
    "\n",
    "        precoComDesconto.append(dadosDesejados2[\"Price\"])\n",
    "        precoSemDesconto.append(dadosDesejados2[\"ListPrice\"])\n",
    "        desconto.append((1 - (dadosDesejados2[\"Price\"]/dadosDesejados2[\"ListPrice\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"marcas\": marcas, \"EAN\": ean, \"Preço com desconto\": precoComDesconto, \"Preço sem desconto\": precoSemDesconto, \"Desconto\": desconto}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportando tudo para um csv\n",
    "df.to_excel('DadosMinasMais.xlsx',sheet_name='Sheet1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
