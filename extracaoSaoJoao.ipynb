{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extração da Drogaria São João"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4325/3822156316.py:8: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "# Import do código\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m marcas\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Criando uma lista de URLs ainda não bem estruturadas\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m urlSuja \u001b[38;5;241m=\u001b[39m \u001b[43mgetNomeMarcas\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m urlLimpa \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Limpando lista das URLs\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 22\u001b[0m, in \u001b[0;36mgetNomeMarcas\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(response\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     21\u001b[0m filtros\u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m\"\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vtex-search-result-3-x-filtersWrapper vtex-search-result-3-x-filtersWrapper--filterDepartament\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 22\u001b[0m sessaoMarcasGrandes \u001b[38;5;241m=\u001b[39m \u001b[43mfiltros\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvtex-search-result-3-x-filterTemplateOverflow vtex-search-result-3-x-filterTemplateOverflow--filterDepartament pb5 overflow-y-auto\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(sessaoMarcasGrandes)\n\u001b[1;32m     24\u001b[0m sessaoMarcas \u001b[38;5;241m=\u001b[39m sessaoMarcasGrandes\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvtex-search-result-3-x-filterTemplateOverflow vtex-search-result-3-x-filterTemplateOverflow--filterDepartament pb5 overflow-y-auto\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find'"
     ]
    }
   ],
   "source": [
    "# Capturando todas as URLs\n",
    "\n",
    "# Função de acessar site\n",
    "all_workers = os.cpu_count()\n",
    "\n",
    "def access_site(url, max_attempts=all_workers):\n",
    "    headers = {'Accept': '*/*', 'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
    "    for retry in range(max_attempts):\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers)\n",
    "            if response.status_code == 200:\n",
    "                return response\n",
    "        except Exception as e:\n",
    "                print(f\"An error occurred while accessing URL: {url}: {e}. Retrying... (Attempt {retry + 1}/{max_attempts})\")\n",
    "                time.sleep(1)\n",
    "\n",
    "# Função captura de todos os nomes de marcas e criação de URLs\n",
    "def getNomeMarcas():\n",
    "    response = access_site(\"https://www.saojoaofarmacias.com.br/medicamentos\")\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    filtros= soup.find(\"div\", class_=\" vtex-search-result-3-x-filtersWrapper vtex-search-result-3-x-filtersWrapper--filterDepartament\")\n",
    "    sessaoMarcasGrandes = filtros.find('div', class_='vtex-search-result-3-x-filterTemplateOverflow vtex-search-result-3-x-filterTemplateOverflow--filterDepartament pb5 overflow-y-auto')\n",
    "    print(sessaoMarcasGrandes)\n",
    "    sessaoMarcas = sessaoMarcasGrandes.find('div', class_='vtex-search-result-3-x-filterTemplateOverflow vtex-search-result-3-x-filterTemplateOverflow--filterDepartament pb5 overflow-y-auto')\n",
    "    print(sessaoMarcas)\n",
    "    marcas = sessaoMarcas.find_all('label', class_='vtex-checkbox__label w-100 c-on-base pointer')\n",
    "    print(marcas)\n",
    "    return marcas\n",
    "\n",
    "# Criando uma lista de URLs ainda não bem estruturadas\n",
    "urlSuja = getNomeMarcas()\n",
    "urlLimpa = []\n",
    "\n",
    "# Limpando lista das URLs\n",
    "for i in urlSuja:\n",
    "    # Criando texto separado e minusculo com \"-\"\n",
    "    texto = i.text.lower()\n",
    "    textoNovo = texto.replace(\" \", \"-\")\n",
    "\n",
    "    # Salvando tudo em uma lista\n",
    "    urlLimpa.append(textoNovo)\n",
    "\n",
    "listaUrls = []\n",
    "\n",
    "# Criando todas as URLs\n",
    "for j in urlLimpa:\n",
    "    URL = \"https://www.saojoaofarmacias.com.br/medicamentos/\" + j + \"?initialMap=c&initialQuery=medicamentos&map=category-1,category-2&page=\"\n",
    "    listaUrls.append(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Achando número de produtos\n",
    "url = \"https://www.drogariasminasmais.com.br/medicamentos/hypera?initialMap=c&initialQuery=medicamentos&map=category-1,brand&page=1\"\n",
    "requisicao = requests.get(url)\n",
    "soup = BeautifulSoup(requisicao.text, 'html.parser')\n",
    "numeroProdutos = soup.find_all('script')[-34].text\n",
    "numeroProdutos = numeroProdutos[:-8].split(\"quantity\")[66:]\n",
    "\n",
    "listaNumeroProdutos = []\n",
    "listaNumeroProdutosCorreta = []\n",
    "\n",
    "for i in numeroProdutos:\n",
    "    listaNumeroProdutos.append(i.split(\",\")[0])\n",
    "\n",
    "for i in listaNumeroProdutos:\n",
    "    aux = i.replace('\"', \"\")\n",
    "    aux = aux.replace(\":\", \"\")\n",
    "    listaNumeroProdutosCorreta.append(int(aux))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função getAllData\n",
    "def getAllData(): \n",
    "    def getJSON(soup):\n",
    "        jsonSujo = soup.find_all('script')[-34].text\n",
    "        jsonSujo = jsonSujo[:-8]\n",
    "        jsonLimpo = jsonSujo.split(\"__STATE__ = \")[1]\n",
    "        return jsonLimpo\n",
    "\n",
    "    total_pages = []\n",
    "\n",
    "    for i in listaNumeroProdutosCorreta:\n",
    "        total_pages.append(math.ceil(i/15))\n",
    "\n",
    "    listaJSON = []\n",
    "    k = 0\n",
    "\n",
    "    for i in listaUrls:\n",
    "        for page_number in total_pages[k:]:\n",
    "            for paginaAtual in range(1, page_number + 1):\n",
    "                url = str(i) + str(paginaAtual)\n",
    "                requisicao = requests.get(url)\n",
    "                soup = BeautifulSoup(requisicao.text, 'html.parser')\n",
    "                listaJSON.append(getJSON(soup))\n",
    "            k = k + 1\n",
    "            break\n",
    "    \n",
    "    return listaJSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de execução rápida\n",
    "all_workers = os.cpu_count()\n",
    "\n",
    "listaJSON = []\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=all_workers) as executor:\n",
    "    # Submeter as tarefas e obter os futuros\n",
    "    futures = [executor.submit(getAllData) for _ in range(1)]\n",
    "    \n",
    "    # Processar os resultados à medida que forem completados\n",
    "    for future in as_completed(futures):\n",
    "        result = future.result()  # Obter o resultado do futuro\n",
    "        if isinstance(result, list):  # Garantir que o resultado seja uma lista\n",
    "            listaJSON.extend(result)  # Adicionar todos os itens da lista à listaJSON\n",
    "        else:\n",
    "            raise ValueError(\"Esperado uma lista de strings, mas obteve um tipo diferente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o JSON e capturando todos os códigos de produtos\n",
    "ean = []\n",
    "precoComDesconto = []\n",
    "precoSemDesconto = []\n",
    "desconto = []\n",
    "marcas = []\n",
    "nomes = []\n",
    "\n",
    "for i in range(0, len(listaJSON)):\n",
    "    dados = json.loads(listaJSON[i])\n",
    "    listaProdutosCerta = []\n",
    "    listaProdutos = []\n",
    "    listaFinal = []\n",
    "    j = 0 \n",
    "\n",
    "    for i in dados.keys():\n",
    "        if i.split(\"$ROOT_QUERY\")[0] == \"\":\n",
    "            break\n",
    "        if j % 18 == 0:\n",
    "            listaProdutos.append(i)\n",
    "        j = j + 1\n",
    "\n",
    "    for i in listaProdutos:\n",
    "            listaProdutosCerta.append(i.split(\".\")[0].replace(\"$\", \"\"))\n",
    "\n",
    "    for i in listaProdutosCerta:\n",
    "        if i.split(\"Product:\")[0] == \"\":\n",
    "            listaFinal.append(i)\n",
    "\n",
    "    # Pegando todos os dados dos produtos\n",
    "    for i in listaFinal:\n",
    "        nomes.append(dados[i][\"productName\"])\n",
    "        marcas.append(dados[i][\"brand\"])\n",
    "\n",
    "    for i in listaFinal:\n",
    "        # Parte do JSON que tem o EAN e precos\n",
    "        localJson1 = str(i) + '.items({\"filter\":\"ALL\"}).0'\n",
    "        dadosDesejados1 = dados.get(localJson1)\n",
    "\n",
    "        ean.append(dadosDesejados1[\"ean\"])\n",
    "\n",
    "    for i in listaFinal:\n",
    "        # Parte do JSON que tem o EAN e precos\n",
    "        localJson2 = \"$\" + str(i) + '.items({\"filter\":\"ALL\"}).0.sellers.0.commertialOffer'\n",
    "        dadosDesejados2 = dados.get(localJson2)\n",
    "\n",
    "        precoComDesconto.append(dadosDesejados2[\"Price\"])\n",
    "        precoSemDesconto.append(dadosDesejados2[\"ListPrice\"])\n",
    "        desconto.append((1 - (dadosDesejados2[\"Price\"]/dadosDesejados2[\"ListPrice\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando dataFrame\n",
    "data = {\"nome\": nomes, \"marcas\": marcas, \"EAN\": ean, \"Preço com desconto\": precoComDesconto, \"Preço sem desconto\": precoSemDesconto, \"Desconto\": desconto}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportando tudo para um excel\n",
    "df.to_excel('DadosMinasMais.xlsx',sheet_name='Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste de getDados\n",
    "def getDados(soup):\n",
    "    jsonSujo = soup.find_all('script')[-34].text\n",
    "    jsonSujo = jsonSujo[:-8]\n",
    "    jsonLimpo = jsonSujo.split(\"__STATE__ = \")[1]\n",
    "    return jsonLimpo\n",
    "\n",
    "total_pages = [25]\n",
    "listaJSON = []\n",
    "\n",
    "for page_number in total_pages:\n",
    "    for paginaAtual in range(1, page_number + 1):\n",
    "        url = \"https://www.drogariasminasmais.com.br/medicamentos/hypera?initialMap=c&initialQuery=medicamentos&map=category-1,brand&page=\" + str(paginaAtual)\n",
    "        requisicao = requests.get(url)\n",
    "        soup = BeautifulSoup(requisicao.text, 'html.parser')\n",
    "        listaJSON.append(getDados(soup))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
